{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Notebook",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-par9xjiVZJ"
      },
      "source": [
        "# Download data using the kaggle api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMTec3vG8bGZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU,  SimpleRNN\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEZwdQiKjAiA",
        "outputId": "a6949dc4-261c-48f2-8b48-72c2f35e7f0f"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "PyGFDqG6ivP4",
        "outputId": "70e8d32f-b310-4418-e9ff-e42c84f7a1e0"
      },
      "source": [
        "# Upload your kaggle api key\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b38be7b3-347a-40a5-90dc-eb752ba21ee8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b38be7b3-347a-40a5-90dc-eb752ba21ee8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEsdHvMWuY59"
      },
      "source": [
        "!rm -r data/\n",
        "!mkdir data/"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJtbtfIiulVC",
        "outputId": "6928c478-2137-47d5-9fdf-2760e7caae8f"
      },
      "source": [
        "!kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove-global-vectors-for-word-representation.zip to /content\n",
            " 96% 439M/458M [00:02<00:00, 204MB/s]\n",
            "100% 458M/458M [00:02<00:00, 180MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-5rUZH1uweg",
        "outputId": "557bf204-f426-4074-b3cb-dbd7ff8fb987"
      },
      "source": [
        "for dirname, _, filenames in os.walk('./'):\n",
        "  for filename in filenames:\n",
        "    if '.zip' in filename:\n",
        "      !unzip $filename\n",
        "      !rm $filename"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove-global-vectors-for-word-representation.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWWX9EcxVy2"
      },
      "source": [
        "!mv glove* data/"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMPzc55oi8-1"
      },
      "source": [
        "%%capture\n",
        "!kaggle competitions download jigsaw-multilingual-toxic-comment-classification"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0ku1FASkFtY",
        "outputId": "bf669709-e468-4aeb-86cd-34c556c8f0ca"
      },
      "source": [
        "for dirname, _, filenames in os.walk('./'):\n",
        "  for filename in filenames:\n",
        "    if '.zip' in filename:\n",
        "      data_file = filename.strip(\".zip\")\n",
        "      !unzip $filename\n",
        "      !mv $data_file data/\n",
        "      !rm $filename\n",
        "      print(f\"\\n{filename} unziped... {data_file} extracted and moved ... {filename} removed\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "test.csv.zip unziped... test.csv extracted and moved ... test.csv.zip removed\n",
            "\n",
            "Archive:  jigsaw-toxic-comment-train.csv.zip\n",
            "  inflating: jigsaw-toxic-comment-train.csv  \n",
            "\n",
            "jigsaw-toxic-comment-train.csv.zip unziped... jigsaw-toxic-comment-train.csv extracted and moved ... jigsaw-toxic-comment-train.csv.zip removed\n",
            "\n",
            "Archive:  jigsaw-toxic-comment-train-processed-seqlen128.csv.zip\n",
            "  inflating: jigsaw-toxic-comment-train-processed-seqlen128.csv  \n",
            "\n",
            "jigsaw-toxic-comment-train-processed-seqlen128.csv.zip unziped... jigsaw-toxic-comment-train-processed-seqlen128.csv extracted and moved ... jigsaw-toxic-comment-train-processed-seqlen128.csv.zip removed\n",
            "\n",
            "Archive:  jigsaw-unintended-bias-train.csv.zip\n",
            "  inflating: jigsaw-unintended-bias-train.csv  \n",
            "\n",
            "jigsaw-unintended-bias-train.csv.zip unziped... jigsaw-unintended-bias-train.csv extracted and moved ... jigsaw-unintended-bias-train.csv.zip removed\n",
            "\n",
            "Archive:  jigsaw-unintended-bias-train-processed-seqlen128.csv.zip\n",
            "  inflating: jigsaw-unintended-bias-train-processed-seqlen128.csv  \n",
            "\n",
            "jigsaw-unintended-bias-train-processed-seqlen128.csv.zip unziped... jigsaw-unintended-bias-train-processed-seqlen128.csv extracted and moved ... jigsaw-unintended-bias-train-processed-seqlen128.csv.zip removed\n",
            "\n",
            "Archive:  test-processed-seqlen128.csv.zip\n",
            "  inflating: test-processed-seqlen128.csv  \n",
            "\n",
            "test-processed-seqlen128.csv.zip unziped... test-processed-seqlen128.csv extracted and moved ... test-processed-seqlen128.csv.zip removed\n",
            "\n",
            "Archive:  validation-processed-seqlen128.csv.zip\n",
            "  inflating: validation-processed-seqlen128.csv  \n",
            "\n",
            "validation-processed-seqlen128.csv.zip unziped... validation-processed-seqlen128.csv extracted and moved ... validation-processed-seqlen128.csv.zip removed\n",
            "\n",
            "Archive:  validation.csv.zip\n",
            "  inflating: validation.csv          \n",
            "\n",
            "validation.csv.zip unziped... validation.csv extracted and moved ... validation.csv.zip removed\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxCmlu2ho3Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3d049c-5973-404f-ed30-3a493b6ead00"
      },
      "source": [
        "i = 0\n",
        "for dirname, _, filenames in os.walk('./data'):\n",
        "  for filename in filenames:\n",
        "    i+=1\n",
        "    print(os.path.join(dirname, filename))\n",
        "print(i, \"files\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./data/sample_submission.csv\n",
            "./data/validation.csv\n",
            "./data/validation-processed-seqlen128.csv\n",
            "./data/test-processed-seqlen128.csv\n",
            "./data/jigsaw-toxic-comment-train.csv\n",
            "./data/test.csv\n",
            "./data/jigsaw-unintended-bias-train-processed-seqlen128.csv\n",
            "./data/glove.6B.100d.txt\n",
            "./data/jigsaw-unintended-bias-train.csv\n",
            "./data/jigsaw-toxic-comment-train-processed-seqlen128.csv\n",
            "./data/glove.6B.200d.txt\n",
            "./data/glove.6B.50d.txt\n",
            "12 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGh_QwPwAQUh"
      },
      "source": [
        "# Recurrent Neural Network Notebook\n",
        "\n",
        "Credit to [tanulsingh077 on kaggle\n",
        "](https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert/notebook)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7koAPlTn8uQ"
      },
      "source": [
        "# Configure Hardware\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itd8XBfn8yCY"
      },
      "source": [
        "# Detect and use hardware\n",
        "def hardware_strategy(use_tpu=False):\n",
        "  if use_tpu:\n",
        "    try:\n",
        "      tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "      print(f\"Running on TPU: {tpu.master()}\")\n",
        "    except ValueError:\n",
        "      tpu = None\n",
        "      print(\"Error: No TPU available\")\n",
        "\n",
        "    if tpu:\n",
        "      tf.config.experimental_connect_to_cluster(tpu)\n",
        "      tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "      print(\"Using TPU\")\n",
        "      return tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    # Default, works on cpu and gpu\n",
        "  print(\"Using CPU\")\n",
        "  return tf.distribute.get_strategy()\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIyowkudD6p3"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL_uflop5yx-"
      },
      "source": [
        "# retreive data\n",
        "train = pd.read_csv('./data/jigsaw-toxic-comment-train.csv')\n",
        "test = pd.read_csv('./data/test.csv')\n",
        "validation = pd.read_csv('./data/validation.csv')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3lHSRdxAIvI"
      },
      "source": [
        "We will be classifying these as good/bad, so we can drop the extra columns for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1Bzb1PzADgo"
      },
      "source": [
        "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'], axis=1, inplace=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auSI79AfAtmG"
      },
      "source": [
        "Use a subset of the data to train faster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W5O11hPdAq4n",
        "outputId": "d31591c0-03a8-48e4-d2be-33af010607e7"
      },
      "source": [
        "train = train.loc[0:12000]\n",
        "train.shape\n",
        "train.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbieWqeMBNwQ"
      },
      "source": [
        "Find the size of the largest comment (for padding later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7gqoeyAy52",
        "outputId": "d8ce8b63-2773-4778-afbc-c317a5e33d4f"
      },
      "source": [
        "largest_comment = train[\"comment_text\"].apply(lambda x: len(str(x).split())).max()\n",
        "largest_comment"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlw3CCEYD1oW"
      },
      "source": [
        "Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVy09uhwBil4"
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train.comment_text.values, \n",
        "                                                                train.toxic.values, \n",
        "                                                                stratify=train.toxic.values,\n",
        "                                                                random_state=42,\n",
        "                                                                test_size=0.2,\n",
        "                                                                shuffle=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwVDDhOjCTma"
      },
      "source": [
        "\"\"\"\n",
        "The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. \n",
        "It is a probability curve that plots the TPR against FPR at various threshold values and essentially separates \n",
        "the ‘signal’ from the ‘noise’. \n",
        "The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes \n",
        "and is used as a summary of the ROC curve.\n",
        "\n",
        "graphs false positive rate (x) vs true positive rate (y)\n",
        "mainly used for binary classification problems\n",
        "\"\"\"\n",
        "def roc_auc(predictions, target):\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "  return metrics.auc(fpr, tpr)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syr2da4aD9mS"
      },
      "source": [
        "# Simple RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvoUnNDhMOJQ"
      },
      "source": [
        "Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s85_TGEADzJL"
      },
      "source": [
        "token = text.Tokenizer()\n",
        "max_len = 150\n",
        "# update internal vocab\n",
        "token.fit_on_texts(list(x_train) + list(x_validation))\n",
        "# tokenize the train and validation set\n",
        "x_train_seq = token.texts_to_sequences(x_train)\n",
        "x_validation_seq = token.texts_to_sequences(x_validation)\n",
        "\n",
        "# zero pad the sequences\n",
        "x_train_pad = sequence.pad_sequences(x_train_seq, maxlen=max_len)\n",
        "x_validation_pad = sequence.pad_sequences(x_validation_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9LgtyF5NOysl",
        "outputId": "f9e7eb0d-b5bd-4059-f7a7-4fa2119e854f"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"\\n\\n Guess who? \\n\\nI have dark wings, a dark/purplish dress, and I\\'m from Rozen Maiden. can you guess who it is?   \\nSuigintou? \\'\\'\\'\\'\\'\\' Talk/Cont \"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqEwlh8EOqbd",
        "outputId": "0f170a67-aecf-4d01-c6af-bcf22233f5d3"
      },
      "source": [
        "x_train_seq[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[664,\n",
              " 65,\n",
              " 7,\n",
              " 19,\n",
              " 2262,\n",
              " 14102,\n",
              " 5,\n",
              " 2262,\n",
              " 20439,\n",
              " 6071,\n",
              " 4,\n",
              " 71,\n",
              " 32,\n",
              " 20440,\n",
              " 6620,\n",
              " 39,\n",
              " 6,\n",
              " 664,\n",
              " 65,\n",
              " 11,\n",
              " 8,\n",
              " 20441,\n",
              " 1502,\n",
              " 38,\n",
              " 6072]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyxBex49NUc2",
        "outputId": "4ed66db2-fee6-4262-f569-8e15810531d6"
      },
      "source": [
        "list(word_index.items())[:5]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1), ('to', 2), ('of', 3), ('and', 4), ('a', 5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5sUmhI_NhQj",
        "outputId": "1fa40c07-bf85-45dc-feb2-045d41e4810f"
      },
      "source": [
        "list(word_index.items())[-5:]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('publicise', 43492),\n",
              " ('gables', 43493),\n",
              " ('plagarize', 43494),\n",
              " ('tibor', 43495),\n",
              " ('unaccurate', 43496)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQPleo20OlaX",
        "outputId": "1de45640-fa34-4802-ae35-15beb71572c0"
      },
      "source": [
        "%%time\n",
        "strategy = hardware_strategy()\n",
        "with strategy.scope():\n",
        "  # A simple RNN without any pretrained embeddings and one dense layer\n",
        "  model = Sequential(name='simple_rnn')\n",
        "  model.add(Embedding(len(word_index)+1, 300, input_length=max_len))\n",
        "  model.add(SimpleRNN(100))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU\n",
            "Model: \"simple_rnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 300)          13049100  \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 100)               40100     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 13,089,301\n",
            "Trainable params: 13,089,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 329 ms, sys: 166 ms, total: 495 ms\n",
            "Wall time: 767 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXp_QAOEPkCX",
        "outputId": "b917c5d9-6153-49b1-ff3a-f647b0fcf444"
      },
      "source": [
        "%%time\n",
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "150/150 [==============================] - 39s 254ms/step - loss: 0.3489 - accuracy: 0.8816\n",
            "Epoch 2/5\n",
            "150/150 [==============================] - 38s 252ms/step - loss: 0.1566 - accuracy: 0.9431\n",
            "Epoch 3/5\n",
            "150/150 [==============================] - 40s 266ms/step - loss: 0.0177 - accuracy: 0.9964\n",
            "Epoch 4/5\n",
            "150/150 [==============================] - 38s 256ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "150/150 [==============================] - 38s 254ms/step - loss: 7.3970e-04 - accuracy: 1.0000\n",
            "CPU times: user 5min 39s, sys: 12.6 s, total: 5min 52s\n",
            "Wall time: 3min 13s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba1e177610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTNBCSiJP9oz",
        "outputId": "ad513455-c5c8-4b95-d66b-8b0df3d17343"
      },
      "source": [
        "scores = model.predict(x_validation_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,y_validation)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc: 0.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2RrjLgGe-VM"
      },
      "source": [
        "scores_model = []\n",
        "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores,y_validation)})"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqwwT8CBt_dG"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn3zg4w-fChw",
        "outputId": "4ce2caa6-c0f1-4042-b496-565727581707"
      },
      "source": [
        "# download word embeddings\n",
        "embeddings_index = {}\n",
        "with open ('./data/glove.6B.200d.txt', 'r', encoding='utf-8') as f:\n",
        "  for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    embeddings = np.asarray([float(x) for x in values[1:]])\n",
        "    embeddings_index[word] = embeddings\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:29, 13599.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfCx9ZCAskTw",
        "outputId": "74306964-48a1-44a0-b866-b4533aaab10c"
      },
      "source": [
        "# create embedding matrix\n",
        "embedding_matrix = np.zeros((len(word_index)+1, 200)) #200 dimensional word embeddings\n",
        "for word, i in tqdm(word_index.items()):\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 43496/43496 [00:00<00:00, 329549.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CkXxunGujgK",
        "outputId": "a1491869-59f6-4d2e-d7ec-ada8b0b60106"
      },
      "source": [
        "%%time\n",
        "strategy = hardware_strategy()\n",
        "with strategy.scope():\n",
        "  # A simple LSTM with glove embeddings and one dense layer\n",
        "  model = Sequential(name='lstm_rnn')\n",
        "  model.add(Embedding(len(word_index)+1,\n",
        "                      200,\n",
        "                      weights=[embedding_matrix],\n",
        "                      input_length=max_len,\n",
        "                      trainable=False))\n",
        "  model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU\n",
            "Model: \"lstm_rnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 200)          8699400   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 8,819,901\n",
            "Trainable params: 120,501\n",
            "Non-trainable params: 8,699,400\n",
            "_________________________________________________________________\n",
            "CPU times: user 311 ms, sys: 230 ms, total: 542 ms\n",
            "Wall time: 382 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRlrBXokvP4q",
        "outputId": "78e7f951-f231-44af-9e38-731a6a2748fa"
      },
      "source": [
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=64 * strategy.num_replicas_in_sync)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "150/150 [==============================] - 68s 439ms/step - loss: 0.2863 - accuracy: 0.9009\n",
            "Epoch 2/5\n",
            "150/150 [==============================] - 66s 439ms/step - loss: 0.1790 - accuracy: 0.9371\n",
            "Epoch 3/5\n",
            "150/150 [==============================] - 66s 442ms/step - loss: 0.1500 - accuracy: 0.9435\n",
            "Epoch 4/5\n",
            "150/150 [==============================] - 66s 443ms/step - loss: 0.1354 - accuracy: 0.9509\n",
            "Epoch 5/5\n",
            "150/150 [==============================] - 66s 440ms/step - loss: 0.1140 - accuracy: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba137c3410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUxO23qPvaoY",
        "outputId": "664a1645-6e0e-4189-be19-0e7ebda86c22"
      },
      "source": [
        "scores = model.predict(x_validation_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,y_validation)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc: 0.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4prHUu5IveSS"
      },
      "source": [
        "scores_model.append({'Model': 'LSTM','AUC_Score': roc_auc(scores,y_validation)})\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOaSIdLJvkk4"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YQepnwrvl8q",
        "outputId": "95de92df-7d21-4731-fb5b-86a643725a8b"
      },
      "source": [
        "%%time\n",
        "strategy = hardware_strategy()\n",
        "with strategy.scope():\n",
        "  # GRU with glove embeddings and two dense layers\n",
        "  model = Sequential(name=\"gru_rnn\")\n",
        "  model.add(Embedding(len(word_index)+1,\n",
        "                      200,\n",
        "                      weights=[embedding_matrix],\n",
        "                      input_length=max_len,\n",
        "                      trainable=False))\n",
        "  model.add(SpatialDropout1D(0.3))\n",
        "  model.add(GRU(200))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU\n",
            "Model: \"gru_rnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 150, 200)          8699400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 150, 200)          0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 200)               241200    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 8,940,801\n",
            "Trainable params: 241,401\n",
            "Non-trainable params: 8,699,400\n",
            "_________________________________________________________________\n",
            "CPU times: user 418 ms, sys: 62 ms, total: 480 ms\n",
            "Wall time: 405 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOY-BLBIwrEx",
        "outputId": "d8e0f49b-baf9-441f-8813-c00cfd7b2cbc"
      },
      "source": [
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=64 * strategy.num_replicas_in_sync)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "150/150 [==============================] - 66s 430ms/step - loss: 0.2892 - accuracy: 0.8995\n",
            "Epoch 2/5\n",
            "150/150 [==============================] - 65s 432ms/step - loss: 0.1596 - accuracy: 0.9439\n",
            "Epoch 3/5\n",
            "150/150 [==============================] - 65s 431ms/step - loss: 0.1264 - accuracy: 0.9562\n",
            "Epoch 4/5\n",
            "150/150 [==============================] - 65s 431ms/step - loss: 0.1128 - accuracy: 0.9591\n",
            "Epoch 5/5\n",
            "150/150 [==============================] - 64s 429ms/step - loss: 0.1038 - accuracy: 0.9625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba1230cad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTW2hBuowsJ-",
        "outputId": "e0298a01-50ba-4123-f10c-14a40a4c3198"
      },
      "source": [
        "scores = model.predict(x_validation_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,y_validation)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc: 0.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWqslhWSwx15"
      },
      "source": [
        "scores_model.append({'Model': 'GRU','AUC_Score': roc_auc(scores,y_validation)})"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuGuDHmawz4Z"
      },
      "source": [
        "Compare the ROC AUC scores between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHXg7JBnwzir",
        "outputId": "62af7d77-a216-4d3f-ac98-fcd750a1d94d"
      },
      "source": [
        "scores_model"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'AUC_Score': 0.8592577882787772, 'Model': 'SimpleRNN'},\n",
              " {'AUC_Score': 0.9687334092539382, 'Model': 'LSTM'},\n",
              " {'AUC_Score': 0.9697384791832996, 'Model': 'GRU'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2xejjvsw-an"
      },
      "source": [
        "# Bi-Directional RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCyXaTOVxAYs",
        "outputId": "37cb4d6e-0cbd-4965-e241-399062941555"
      },
      "source": [
        "%%time\n",
        "strategy = hardware_strategy()\n",
        "with strategy.scope():\n",
        "  model=Sequential(name=\"bidirectional\")\n",
        "  model.add(Embedding(len(word_index)+1,\n",
        "                      200,\n",
        "                      weights=[embedding_matrix],\n",
        "                      input_length=max_len,\n",
        "                      trainable=False))\n",
        "  model.add(Bidirectional(LSTM(200, dropout=0.3, recurrent_dropout=0.3)))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU\n",
            "Model: \"bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 150, 200)          8699400   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 400)               641600    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 401       \n",
            "=================================================================\n",
            "Total params: 9,341,401\n",
            "Trainable params: 642,001\n",
            "Non-trainable params: 8,699,400\n",
            "_________________________________________________________________\n",
            "CPU times: user 482 ms, sys: 91.2 ms, total: 573 ms\n",
            "Wall time: 488 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MD7IKnk41Mr",
        "outputId": "77dccf0c-5a9d-457d-8e4c-278500ae4e3e"
      },
      "source": [
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=64 * strategy.num_replicas_in_sync)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "150/150 [==============================] - 321s 2s/step - loss: 0.2786 - accuracy: 0.9023\n",
            "Epoch 2/5\n",
            "150/150 [==============================] - 323s 2s/step - loss: 0.1746 - accuracy: 0.9361\n",
            "Epoch 3/5\n",
            "150/150 [==============================] - 314s 2s/step - loss: 0.1326 - accuracy: 0.9498\n",
            "Epoch 4/5\n",
            "150/150 [==============================] - 313s 2s/step - loss: 0.1230 - accuracy: 0.9520\n",
            "Epoch 5/5\n",
            "150/150 [==============================] - 313s 2s/step - loss: 0.1146 - accuracy: 0.9593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba10b7e890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FsTMjKB42T5",
        "outputId": "749c9394-4086-4590-ad47-f19a5857f9ea"
      },
      "source": [
        "scores = model.predict(x_validation_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,y_validation)))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc: 0.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLNpL8se45IS"
      },
      "source": [
        "scores_model.append({'Model': 'Bi-Directional LSTM','AUC_Score': roc_auc(scores,y_validation)})"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doEsppHe49Zu",
        "outputId": "705e58e8-3e80-4483-8c06-89a66200397d"
      },
      "source": [
        "scores_model"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'AUC_Score': 0.8592577882787772, 'Model': 'SimpleRNN'},\n",
              " {'AUC_Score': 0.9687334092539382, 'Model': 'LSTM'},\n",
              " {'AUC_Score': 0.9697384791832996, 'Model': 'GRU'},\n",
              " {'AUC_Score': 0.9705733356568822, 'Model': 'Bi-Directional LSTM'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6z9t3di1G0Z"
      },
      "source": [
        "# Seq2Seq Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpOdsKQb1LZo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bMkWrkp1MU4"
      },
      "source": [
        "# Attention Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77owF3Qa1L4y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdWkIBXF1OXV"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plLh1-1o1PSQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}